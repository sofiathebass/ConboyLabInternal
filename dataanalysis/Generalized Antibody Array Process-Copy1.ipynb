{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e59d4e1f-81dc-4f14-90b2-972add8bbf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /srv/conda/lib/python3.11/site-packages (3.1.3)\n",
      "Requirement already satisfied: et-xmlfile in /srv/conda/lib/python3.11/site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from statistics import mean\n",
    "import copy\n",
    "import sys\n",
    "!{sys.executable} -m pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8831ad85-de1c-48f5-b3bd-7e48bdfd933f",
   "metadata": {},
   "source": [
    "<h1>Generalized Antibody Array Process</h1>\n",
    "<h2>Overall Process</h2>\n",
    "<ul>\n",
    "    <li>Collect and Parse Antibody Arrays to be Compared</li>\n",
    "    <li>Calculate probability of being negative controls by subarray</li>\n",
    "    <li>Normalize to negative controls by subarray</li>\n",
    "    <li>Method 1. Normalize to lowest positive control value (average of Positive 3 values) by subarray</li>\n",
    "    <li>Method 2. Normalize to each control based on the value of the point</li>\n",
    "    <li>Calculate Log 2 Fold Change of interested differences</li>\n",
    "    <li>Sample visualizations of what I'm doing/showing</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9272790c-379b-47db-9b27-d3752f3da0b2",
   "metadata": {},
   "source": [
    "<h2>Collect and Parse Antibody Arrays to be Compared</h2>\n",
    "<h4>This is where we'll define most of our variables</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "441b51c7-67df-439d-b0a9-354cc120ff1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Block</th>\n",
       "      <th>Column</th>\n",
       "      <th>Row</th>\n",
       "      <th>Name</th>\n",
       "      <th>ID</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Dia.</th>\n",
       "      <th>F532 Median</th>\n",
       "      <th>F532 Mean</th>\n",
       "      <th>...</th>\n",
       "      <th>Sum of Medians (1/532)</th>\n",
       "      <th>Sum of Means (1/532)</th>\n",
       "      <th>Log Ratio (1/532)</th>\n",
       "      <th>F532 Median - B532</th>\n",
       "      <th>F532 Mean - B532</th>\n",
       "      <th>F532 Total Intensity</th>\n",
       "      <th>SNR 532</th>\n",
       "      <th>Flags</th>\n",
       "      <th>Normalize</th>\n",
       "      <th>Autoflag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive 1</td>\n",
       "      <td>Positive 1</td>\n",
       "      <td>4840</td>\n",
       "      <td>55650</td>\n",
       "      <td>180</td>\n",
       "      <td>21089</td>\n",
       "      <td>15930</td>\n",
       "      <td>...</td>\n",
       "      <td>21056</td>\n",
       "      <td>15897</td>\n",
       "      <td>Error</td>\n",
       "      <td>21056</td>\n",
       "      <td>15897</td>\n",
       "      <td>4078062</td>\n",
       "      <td>1589.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive 1</td>\n",
       "      <td>Positive 1</td>\n",
       "      <td>5250</td>\n",
       "      <td>55650</td>\n",
       "      <td>170</td>\n",
       "      <td>24824</td>\n",
       "      <td>19930</td>\n",
       "      <td>...</td>\n",
       "      <td>24789</td>\n",
       "      <td>19895</td>\n",
       "      <td>Error</td>\n",
       "      <td>24789</td>\n",
       "      <td>19895</td>\n",
       "      <td>4145424</td>\n",
       "      <td>196.941</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive 2</td>\n",
       "      <td>Positive 2</td>\n",
       "      <td>5670</td>\n",
       "      <td>55630</td>\n",
       "      <td>190</td>\n",
       "      <td>6910</td>\n",
       "      <td>9423</td>\n",
       "      <td>...</td>\n",
       "      <td>6876</td>\n",
       "      <td>9389</td>\n",
       "      <td>Error</td>\n",
       "      <td>6876</td>\n",
       "      <td>9389</td>\n",
       "      <td>2412277</td>\n",
       "      <td>853.364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive 2</td>\n",
       "      <td>Positive 2</td>\n",
       "      <td>6080</td>\n",
       "      <td>55630</td>\n",
       "      <td>180</td>\n",
       "      <td>7111</td>\n",
       "      <td>10032</td>\n",
       "      <td>...</td>\n",
       "      <td>7077</td>\n",
       "      <td>9998</td>\n",
       "      <td>Error</td>\n",
       "      <td>7077</td>\n",
       "      <td>9998</td>\n",
       "      <td>2568078</td>\n",
       "      <td>999.600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive 3</td>\n",
       "      <td>Positive 3</td>\n",
       "      <td>6480</td>\n",
       "      <td>55630</td>\n",
       "      <td>170</td>\n",
       "      <td>2007</td>\n",
       "      <td>2269</td>\n",
       "      <td>...</td>\n",
       "      <td>1972</td>\n",
       "      <td>2234</td>\n",
       "      <td>Error</td>\n",
       "      <td>1972</td>\n",
       "      <td>2234</td>\n",
       "      <td>471870</td>\n",
       "      <td>223.300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Block  Column  Row        Name          ID     X      Y  Dia.  F532 Median  \\\n",
       "0      1       1    1  Positive 1  Positive 1  4840  55650   180        21089   \n",
       "1      1       2    1  Positive 1  Positive 1  5250  55650   170        24824   \n",
       "2      1       3    1  Positive 2  Positive 2  5670  55630   190         6910   \n",
       "3      1       4    1  Positive 2  Positive 2  6080  55630   180         7111   \n",
       "4      1       5    1  Positive 3  Positive 3  6480  55630   170         2007   \n",
       "\n",
       "   F532 Mean  ...  Sum of Medians (1/532)  Sum of Means (1/532)  \\\n",
       "0      15930  ...                   21056                 15897   \n",
       "1      19930  ...                   24789                 19895   \n",
       "2       9423  ...                    6876                  9389   \n",
       "3      10032  ...                    7077                  9998   \n",
       "4       2269  ...                    1972                  2234   \n",
       "\n",
       "   Log Ratio (1/532)  F532 Median - B532  F532 Mean - B532  \\\n",
       "0              Error               21056             15897   \n",
       "1              Error               24789             19895   \n",
       "2              Error                6876              9389   \n",
       "3              Error                7077              9998   \n",
       "4              Error                1972              2234   \n",
       "\n",
       "   F532 Total Intensity   SNR 532  Flags  Normalize  Autoflag  \n",
       "0               4078062  1589.500      0          0         0  \n",
       "1               4145424   196.941      0          0         0  \n",
       "2               2412277   853.364      0          0         0  \n",
       "3               2568078   999.600      0          0         0  \n",
       "4                471870   223.300      0          0         0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add in your spreadsheet files, I'm using four different ones \n",
    "\n",
    "df_of = pd.read_excel(\"OF_lysate.xlsx\")\n",
    "df_yf = pd.read_excel(\"YF_lysate.xlsx\")\n",
    "df_om = pd.read_excel(\"OM_lysate.xlsx\")\n",
    "df_ym = pd.read_excel(\"YM_lysate.xlsx\")\n",
    "\n",
    "all_dfs = [df_of, df_yf, df_ym, df_om] #This is super important! List all your arrays that you will want to compare here after import\n",
    "amt_dfs = len(all_dfs)\n",
    "\n",
    "#Reading one of the files, make sure it imported properly! You'll most likely have to take out the metadata for it to work\n",
    "df_yf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55de4bd1-0587-45ae-be6f-bf392cc299c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an array with just the protein ID and F532 Total Intensity (the only two columns we use in the analysis)\n",
    "#Stored in a list of 2d Arrays\n",
    "\n",
    "paired_data = [[] for i in range(amt_dfs)]\n",
    "for dataframe_i in range(len(all_dfs)):\n",
    "    for index, row in all_dfs[dataframe_i].iterrows():\n",
    "        paired_data[dataframe_i].append([row['ID'], row['F532 Total Intensity']])\n",
    "\n",
    "#Reading the list\n",
    "#print(paired_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd9673c1-cd56-46e9-832a-17cd8fa858af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of all negative control values for each array, human uses _NCTRL but your array might be different\n",
    "\n",
    "negs = [[] for i in range(amt_dfs)]\n",
    "\n",
    "for i in range(len(paired_data)):\n",
    "    for row in paired_data[i]:\n",
    "        if row[0] == \"_NCTRL\":\n",
    "            negs[i].append(row[1])\n",
    "\n",
    "#Reading the list (shouldn't be too long), check for outliers here \n",
    "#print(negs)\n",
    "\n",
    "negs = [[val for val in dataframe if val != 243168] for dataframe in negs] #this is me removing an outlier\n",
    "\n",
    "#Same list without outliers\n",
    "#print(negs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a73a446-51c1-4662-a0af-bd446bdee828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2984.131556087873, 1366.491166294797, 1949.2115598024518, 4191.69166633983]\n"
     ]
    }
   ],
   "source": [
    "#Get the average of the negative controls (to normalize to later!) for each array \n",
    "neg_control = [stats.gmean(negs[i]) for i in range(len(negs))]\n",
    "\n",
    "#Check that average makes sense, revise outliers list if not \n",
    "print(neg_control)\n",
    "\n",
    "#remove the negative control values from the paired data, unnecessary to keep them in your final data! \n",
    "paired_data = [list(filter(lambda row: row[0] != \"_NCTRL\", paired_data[dataframe])) for dataframe in range(amt_dfs)]\n",
    "\n",
    "#Check that paired data filters properly\n",
    "#print(paired_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f240fcb-0428-406c-add4-823c60528704",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pair up antibody array duplicates into a single averaged value, we're going to be using mean but I added stdev to flag any outliers early and easily\n",
    "\n",
    "single_data = [[] for i in range(amt_dfs)]\n",
    "\n",
    "for i in range(len(paired_data)):\n",
    "    for j in range(0, len(paired_data[i]), 2):\n",
    "        pair = [paired_data[i][j][1], paired_data[i][j+1][1]]\n",
    "        single_data[i].append([paired_data[i][j][0], mean(pair)])\n",
    "\n",
    "#Check that paired values make sense! \n",
    "#single_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c49e1b6-48b6-44b9-bc19-f8a418bbbb86",
   "metadata": {},
   "source": [
    "<h2>Calculate probability of being negative controls by subarray</h2>\n",
    "<h4>This checks whether the results with the most amount of relative change are both positive, and gates if a result stops being made at all in different conditions</h4>\n",
    "\n",
    "<p>The way I do it in this analysis is bootstrap the negative controls to create a probability space where I can calculate the probability something is a false positive, and the p value for that. In volcano graphs this is shown as -log10 p value. We'll normalize a step after so if you feel this is unnecessary skip the code block, it doesn't change anything in later steps</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56b85c18-3cc2-4b40-9c97-fa2058c932f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Proteins  OF -log10 p_value  OM -log10 p_value  \\\n",
      "3                     6Ckineâ€            4.015890           9.999989   \n",
      "4                  Activin Aâ€            3.653486           8.480965   \n",
      "5                   Activin B           4.241150           5.430277   \n",
      "6                   Activin C          10.000000          10.000000   \n",
      "7         Activin RIA / ALK-2          10.000000          10.000000   \n",
      "8         Activin RIB / ALK-4           6.689898          10.000000   \n",
      "9             Activin RII A/B           2.465328           3.381625   \n",
      "10               Activin RIIA          10.000000          10.000000   \n",
      "11       Adiponectin / Acrp30          10.000000          10.000000   \n",
      "12                       AgRP          10.000000          10.000000   \n",
      "13                      ALCAM           3.428555           5.921840   \n",
      "14                 Angiogenin           1.106913           4.366235   \n",
      "15             Angiopoietin-1           3.241112           4.336488   \n",
      "16             Angiopoietin-2          10.000000          10.000000   \n",
      "17             Angiopoietin-4           2.995840           4.681013   \n",
      "18        Angiopoietin-like 1          10.000000          10.000000   \n",
      "19        Angiopoietin-like 2           1.030127           3.008010   \n",
      "20  Angiopoietin-like Factorâ€            0.097895           3.242255   \n",
      "21               Angiostatinâ€           10.000000          10.000000   \n",
      "22                        APJ          10.000000          10.000000   \n",
      "23                     APRILâ€           10.000000          10.000000   \n",
      "24          AR (Amphiregulin)           2.809403           9.984516   \n",
      "25                    Artemin           0.535129           2.417371   \n",
      "26                        Axl           3.026763           9.912142   \n",
      "27                 B7-1 /CD80           4.412014           9.689831   \n",
      "28         BAFF R / TNFRSF13C           0.311551           2.144410   \n",
      "29            BCMA / TNFRSF17           0.172557           2.760605   \n",
      "30                       BD-1          10.000000          10.000000   \n",
      "31                      BDNFâ€           10.000000          10.000000   \n",
      "32               beta-Catenin           5.734951           7.623315   \n",
      "\n",
      "    YF -log10 p_value  YM -log10 p_value  \n",
      "3           10.000000          10.000000  \n",
      "4           10.000000          10.000000  \n",
      "5           10.000000          10.000000  \n",
      "6           10.000000          10.000000  \n",
      "7           10.000000          10.000000  \n",
      "8           10.000000          10.000000  \n",
      "9            9.996776           9.996653  \n",
      "10          10.000000          10.000000  \n",
      "11          10.000000          10.000000  \n",
      "12          10.000000          10.000000  \n",
      "13          10.000000          10.000000  \n",
      "14          10.000000          10.000000  \n",
      "15           8.145863           9.988710  \n",
      "16          10.000000          10.000000  \n",
      "17          10.000000          10.000000  \n",
      "18          10.000000          10.000000  \n",
      "19           6.398470           5.401217  \n",
      "20           9.999998          10.000000  \n",
      "21          10.000000          10.000000  \n",
      "22          10.000000          10.000000  \n",
      "23          10.000000          10.000000  \n",
      "24           5.064049          10.000000  \n",
      "25           9.249481          10.000000  \n",
      "26          10.000000          10.000000  \n",
      "27          10.000000          10.000000  \n",
      "28           0.990798           9.982720  \n",
      "29           9.999999          10.000000  \n",
      "30          10.000000          10.000000  \n",
      "31          10.000000          10.000000  \n",
      "32          10.000000          10.000000  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Proteins</th>\n",
       "      <th>Average Young</th>\n",
       "      <th>Average Old</th>\n",
       "      <th>Max value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6Ckineâ€ </td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.007939</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Activin Aâ€ </td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.067226</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Activin B</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.835714</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Activin C</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Activin RIA / ALK-2</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Activin RIB / ALK-4</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.344949</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Activin RII A/B</td>\n",
       "      <td>9.996714</td>\n",
       "      <td>2.923477</td>\n",
       "      <td>9.996714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Activin RIIA</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Adiponectin / Acrp30</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AgRP</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ALCAM</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.675197</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Angiogenin</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.736574</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Angiopoietin-1</td>\n",
       "      <td>9.067286</td>\n",
       "      <td>3.788800</td>\n",
       "      <td>9.067286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Angiopoietin-2</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Angiopoietin-4</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.838426</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Angiopoietin-like 1</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Angiopoietin-like 2</td>\n",
       "      <td>5.899843</td>\n",
       "      <td>2.019069</td>\n",
       "      <td>5.899843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Angiopoietin-like Factorâ€ </td>\n",
       "      <td>9.999999</td>\n",
       "      <td>1.670075</td>\n",
       "      <td>9.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Angiostatinâ€ </td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>APJ</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>APRILâ€ </td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AR (Amphiregulin)</td>\n",
       "      <td>7.532024</td>\n",
       "      <td>6.396959</td>\n",
       "      <td>7.532024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Artemin</td>\n",
       "      <td>9.624740</td>\n",
       "      <td>1.476250</td>\n",
       "      <td>9.624740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Axl</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.469452</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>B7-1 /CD80</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.050923</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BAFF R / TNFRSF13C</td>\n",
       "      <td>5.486759</td>\n",
       "      <td>1.227981</td>\n",
       "      <td>5.486759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BCMA / TNFRSF17</td>\n",
       "      <td>9.999999</td>\n",
       "      <td>1.466581</td>\n",
       "      <td>9.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>BD-1</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>BDNFâ€ </td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>beta-Catenin</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.679133</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Proteins  Average Young  Average Old  Max value\n",
       "3                     6Ckineâ€       10.000000     7.007939  10.000000\n",
       "4                  Activin Aâ€       10.000000     6.067226  10.000000\n",
       "5                   Activin B      10.000000     4.835714  10.000000\n",
       "6                   Activin C      10.000000    10.000000  10.000000\n",
       "7         Activin RIA / ALK-2      10.000000    10.000000  10.000000\n",
       "8         Activin RIB / ALK-4      10.000000     8.344949  10.000000\n",
       "9             Activin RII A/B       9.996714     2.923477   9.996714\n",
       "10               Activin RIIA      10.000000    10.000000  10.000000\n",
       "11       Adiponectin / Acrp30      10.000000    10.000000  10.000000\n",
       "12                       AgRP      10.000000    10.000000  10.000000\n",
       "13                      ALCAM      10.000000     4.675197  10.000000\n",
       "14                 Angiogenin      10.000000     2.736574  10.000000\n",
       "15             Angiopoietin-1       9.067286     3.788800   9.067286\n",
       "16             Angiopoietin-2      10.000000    10.000000  10.000000\n",
       "17             Angiopoietin-4      10.000000     3.838426  10.000000\n",
       "18        Angiopoietin-like 1      10.000000    10.000000  10.000000\n",
       "19        Angiopoietin-like 2       5.899843     2.019069   5.899843\n",
       "20  Angiopoietin-like Factorâ€        9.999999     1.670075   9.999999\n",
       "21               Angiostatinâ€       10.000000    10.000000  10.000000\n",
       "22                        APJ      10.000000    10.000000  10.000000\n",
       "23                     APRILâ€       10.000000    10.000000  10.000000\n",
       "24          AR (Amphiregulin)       7.532024     6.396959   7.532024\n",
       "25                    Artemin       9.624740     1.476250   9.624740\n",
       "26                        Axl      10.000000     6.469452  10.000000\n",
       "27                 B7-1 /CD80      10.000000     7.050923  10.000000\n",
       "28         BAFF R / TNFRSF13C       5.486759     1.227981   5.486759\n",
       "29            BCMA / TNFRSF17       9.999999     1.466581   9.999999\n",
       "30                       BD-1      10.000000    10.000000  10.000000\n",
       "31                      BDNFâ€       10.000000    10.000000  10.000000\n",
       "32               beta-Catenin      10.000000     6.679133  10.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negs_series = [pd.Series(neg) for neg in negs]\n",
    "neg_spread = [subarray.sample(5000, replace=True) for subarray in negs_series]\n",
    "results = [[] for i in range(amt_dfs)]\n",
    "\n",
    "for i in range(amt_dfs):\n",
    "    mu, std = norm.fit(negs_series[i])\n",
    "    \n",
    "    id = [datapoint[0] for datapoint in single_data[i]]\n",
    "    observed_value = [datapoint[1] for datapoint in single_data[i]]\n",
    "    \n",
    "    results[i] = pd.DataFrame({\n",
    "        'id': id,\n",
    "        'observed_value': observed_value,\n",
    "        'prob_negative': norm.cdf(observed_value, loc=mu, scale=std)\n",
    "    })\n",
    "    \n",
    "    results[i].sort_values(\"prob_negative\")\n",
    "    \n",
    "    results[i][\"p_value\"] = 1 - results[i][\"prob_negative\"]\n",
    "    results[i][\"-log10 p_value\"] = -np.log10(results[i][\"p_value\"] + 1e-10)\n",
    "    \n",
    "    results[i] = results[i].drop(columns=\"prob_negative\")\n",
    "    results[i].sort_values(\"id\", ascending=True)\n",
    "\n",
    "#print each dataframe if you would like\n",
    "# print(results[0].head())\n",
    "\n",
    "#make one df with everything that can be exported \n",
    "merged_df = pd.concat(results, axis=1, ignore_index=True)\n",
    "\n",
    "#\n",
    "#IMPORTANTTTTT!!!!!!!! For anyone using this for their arrays, it's not important for understanding the code\n",
    "#\n",
    "\n",
    "#rename columns after merge in order of how you loaded the arrays in the second code block, I used my df names of, yf, ym, om\n",
    "rename_list = ['OF id', 'OF observed_value', 'OF prob_negative', 'OF -log10 p_value', 'YF id', 'YF observed_value', 'YF prob_negative', 'YF -log10 p_value', 'YM id', 'YM observed_value', 'YM prob_negative', 'YM -log10 p_value', 'OM id', 'OM observed_value', 'OM prob_negative', 'OM -log10 p_value']\n",
    "merged_df.columns = rename_list\n",
    "\n",
    "#\n",
    "#IMPORTANTTTTT!!!!!!!! For anyone using this for their arrays, it's not important for understanding the code\n",
    "#\n",
    "\n",
    "#double check, does this make sense?\n",
    "#print(rename_list)\n",
    "#print(merged_df)\n",
    "\n",
    "#export df to a csv file so you can use it in graphs in your favorite graph generator\n",
    "results_df = pd.DataFrame(data = merged_df)\n",
    "results_df = results_df[(results_df[\"OF id\"] != \"Positive 1\") & (results_df[\"OF id\"] != \"Positive 2\") & (results_df[\"OF id\"] != \"Positive 3\") & (results_df[\"OF id\"] != \"_NCTRL\")]\n",
    "results_df = results_df[[\"OF id\", \"OF -log10 p_value\", \"OM -log10 p_value\", \"YF -log10 p_value\", \"YM -log10 p_value\"]].rename(columns={\"OF id\": \"Proteins\"})\n",
    "print(results_df.head(30))\n",
    "\n",
    "#this is for my analysis only \n",
    "results_df[\"Average Young\"] = (results_df[\"YF -log10 p_value\"] + results_df[\"YM -log10 p_value\"])/2\n",
    "results_df[\"Average Old\"] = (results_df[\"OF -log10 p_value\"] + results_df[\"OM -log10 p_value\"])/2\n",
    "results_df[\"Max value\"] = results_df[[\"Average Young\", \"Average Old\"]].max(axis=1)\n",
    "\n",
    "results_df = results_df[[\"Proteins\", \"Average Young\", \"Average Old\", \"Max value\"]]\n",
    "\n",
    "results_df.to_csv(\"false_positive_probability.csv\")\n",
    "results_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c1a7f95-de6d-4e06-9630-db1c9ada01e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_91/2440383777.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  results[0].sort_values(\"observed_value\", ascending=False)[results[0][\"p_value\"] < 0.0101]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>observed_value</th>\n",
       "      <th>p_value</th>\n",
       "      <th>-log10 p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive 1</td>\n",
       "      <td>3541653.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Positive 1</td>\n",
       "      <td>2895633.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive 2</td>\n",
       "      <td>1811528.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>Positive 1</td>\n",
       "      <td>1553660.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Coagulation Factor III / Tissue Factor</td>\n",
       "      <td>1514704.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>ICAM-1</td>\n",
       "      <td>10231.0</td>\n",
       "      <td>0.005538</td>\n",
       "      <td>2.256668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>IL-13 R alpha 2</td>\n",
       "      <td>10220.5</td>\n",
       "      <td>0.005603</td>\n",
       "      <td>2.251576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>ENA-78</td>\n",
       "      <td>10131.5</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>2.208682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>MMP-9â€ </td>\n",
       "      <td>9742.5</td>\n",
       "      <td>0.009401</td>\n",
       "      <td>2.026807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>Thymopoietinâ€ </td>\n",
       "      <td>9685.5</td>\n",
       "      <td>0.009979</td>\n",
       "      <td>2.000921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  observed_value   p_value  \\\n",
       "0                                Positive 1       3541653.0  0.000000   \n",
       "284                              Positive 1       2895633.5  0.000000   \n",
       "1                                Positive 2       1811528.5  0.000000   \n",
       "515                              Positive 1       1553660.5  0.000000   \n",
       "76   Coagulation Factor III / Tissue Factor       1514704.5  0.000000   \n",
       "..                                      ...             ...       ...   \n",
       "210                                  ICAM-1         10231.0  0.005538   \n",
       "271                         IL-13 R alpha 2         10220.5  0.005603   \n",
       "112                                  ENA-78         10131.5  0.006185   \n",
       "362                                  MMP-9â€           9742.5  0.009401   \n",
       "466                           Thymopoietinâ€           9685.5  0.009979   \n",
       "\n",
       "     -log10 p_value  \n",
       "0         10.000000  \n",
       "284       10.000000  \n",
       "1         10.000000  \n",
       "515       10.000000  \n",
       "76        10.000000  \n",
       "..              ...  \n",
       "210        2.256668  \n",
       "271        2.251576  \n",
       "112        2.208682  \n",
       "362        2.026807  \n",
       "466        2.000921  \n",
       "\n",
       "[311 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print each dataframe if you would like\n",
    "#print(results[0].head(40))\n",
    "results[0].sort_values(\"observed_value\", ascending=False)[results[0][\"p_value\"] < 0.0101]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc122b6-535c-4c36-987e-fc7ac63ae485",
   "metadata": {},
   "source": [
    "<h2>Normalize to negative controls by subarray</h2>\n",
    "<h4>Here this just means divide subarray by average of negative controls, can also subtract, not sure which makes more sense here so I coded options </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e236ce8c-5d3e-4e8c-baff-03a65ae629ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WARNING: Rerun all cells rather than running this cell multiple times, it'll keep dividing smaller and smaller since we're not updating a copy\n",
    "\n",
    "#To divide \n",
    "# for i in range(len(single_data)):\n",
    "#     for row in single_data[i]:\n",
    "#         row[1] = row[1] / neg_control[i]\n",
    "\n",
    "# for i in range(len(paired_data)):\n",
    "#     for row in paired_data[i]:\n",
    "#         row[1] = row[1] / neg_control[i]    \n",
    "\n",
    "#To substract \n",
    "for i in range(len(single_data)):\n",
    "    for row in single_data[i]:\n",
    "        row[1] = row[1] - neg_control[i]\n",
    "\n",
    "for i in range(len(paired_data)):\n",
    "    for row in paired_data[i]:\n",
    "        row[1] = row[1] / neg_control[i] \n",
    "\n",
    "#Check it seems properly divided/subtracted \n",
    "#print(single_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd43d34a-af51-4edc-8e49-7cff91c599c3",
   "metadata": {},
   "source": [
    "<h2>Normalize to lowest positive control value (average of Positive 3 values) by subarray</h2>\n",
    "<h4>This will involve finding the average of the lowest positive control values, then dividing values by it.\n",
    "The idea of this is to get a \"unit\" of measurement that's the lowest positive unit so differences make sense</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a6fa031-54cd-4287-90a5-d5ba2777533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating copies of anything that might get overridden because there are two normalization options\n",
    "\n",
    "paired_data_1 = copy.deepcopy(paired_data)\n",
    "single_data_1 = copy.deepcopy(single_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7f13e70-1917-4839-a07f-a5f67f44f2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[126.14189184523859, 142.554372018937, 269.5035339039583, 297.02075238331076, 137.71209220371878, 142.7048345543718], [345.3150753103384, 385.0365175990405, 598.8951997538544, 673.5352724566708, 317.0536412428835, 316.023265024779], [202.5249634985791, 232.07742521588906, 367.8497577105833, 424.11045422067076, 194.6294634321011, 209.05734831641308], [136.60212763215645, 163.5690443325691, 282.6632048140591, 324.2564358715902, 147.9493362978007, 156.98077348675227]]\n"
     ]
    }
   ],
   "source": [
    "#Create a list of all the lowest positive control values for each array, human uses Positive 3 but your array might be different\n",
    "\n",
    "poss = [[] for i in range(amt_dfs)]\n",
    "\n",
    "for i in range(amt_dfs):\n",
    "    for row in paired_data_1[i]:\n",
    "        if row[0] == \"Positive 3\":\n",
    "            poss[i].append(row[1])\n",
    "\n",
    "#Reading the list (shouldn't be too long), check for outliers here \n",
    "print(poss)\n",
    "\n",
    "#poss = [[val for val in dataframe if val != 243168] for dataframe in poss] #I have no outliers but if I did I'd do something like this\n",
    "\n",
    "#Same list without outliers\n",
    "#print(poss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "733e4ec3-5783-447c-bc1f-6f519e109132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the average of the positive 3 controls\n",
    "pos_control = [stats.gmean(poss[i]) for i in range(len(poss))]\n",
    "\n",
    "#Check that average makes sense, revise outliers list if not \n",
    "#Keep in mind that this was already normalized to the negative control so it might be a tad lower than expected\n",
    "#print(pos_control)\n",
    "\n",
    "#remove the positive 3 control values from the paired data, unnecessary to keep them in your final data since we're going to normalize to them\n",
    "single_data_1 = [list(filter(lambda row: row[0] != \"Positive 3\", single_data_1[dataframe])) for dataframe in range(amt_dfs)]\n",
    "paired_data_1 = [list(filter(lambda row: row[0] != \"Positive 3\", paired_data_1[dataframe])) for dataframe in range(amt_dfs)]\n",
    "\n",
    "#Check that paired data filters properly\n",
    "#print(single_data)\n",
    "#print(paired_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d2e73d1-cdda-4ae2-8187-418a5214f68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize to Positive 3 by dividing positive 3 average \n",
    "\n",
    "#WARNING: Rerun all cells rather than running this cell multiple times, it'll keep dividing smaller and smaller since we're not updating a copy\n",
    "\n",
    "for i in range(len(single_data_1)):\n",
    "    for row in single_data_1[i]:\n",
    "        row[1] = row[1] / pos_control[i]\n",
    "\n",
    "for i in range(len(paired_data_1)):\n",
    "    for row in paired_data_1[i]:\n",
    "        row[1] = row[1] / pos_control[i]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a7fc5ce-df3f-4cf3-a44c-7c4e3b250604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check that positive control 1 and 2 make sense to this normalization (should be a clear difference if you're within working protein content)\n",
    "\n",
    "other_poss = [[] for i in range(amt_dfs)]\n",
    "\n",
    "for i in range(amt_dfs):\n",
    "    for row in single_data_1[i]:\n",
    "        if row[0] == \"Positive 1\" or row[0] == \"Positive 2\":\n",
    "            other_poss[i].append([row[0], row[1]])\n",
    "\n",
    "#remove the other positive controls from data, unnecessary to keep them in your final data\n",
    "single_data_1 = [list(filter(lambda row: row[0] != \"Positive 1\", single_data_1[dataframe])) for dataframe in range(amt_dfs)]\n",
    "paired_data_1 = [list(filter(lambda row: row[0] != \"Positive 1\", paired_data_1[dataframe])) for dataframe in range(amt_dfs)]\n",
    "single_data_1 = [list(filter(lambda row: row[0] != \"Positive 2\", single_data_1[dataframe])) for dataframe in range(amt_dfs)]\n",
    "paired_data_1 = [list(filter(lambda row: row[0] != \"Positive 2\", paired_data_1[dataframe])) for dataframe in range(amt_dfs)]\n",
    "\n",
    "#print(other_poss)\n",
    "#print(single_data_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083c0c96-5e5d-4222-b543-544452ec3363",
   "metadata": {},
   "source": [
    "<h2>You can either normalize to Positive 3 or this other way</h2>\n",
    "<h4>Take the average of positive 1, 2, and 3 as three y axis units, with negative control at 0, to make a linear expression</h4>\n",
    "<p>Caveat is RayBiotech hasn't responded to me yet so I'm not sure where positive 1, 2, 3 are on the scale, but assuming they respond to me at some point the idea is if increasing fluorescence isn't linear then this will show it better because each positive is higher than the next by a (theoretically) known amount.</p>\n",
    "<p>Basically, theoretically the values could be log change, right now I'm making each positive one unit so there's a linear difference between them which is slightly rougher than a smooth curve difference but I think the most accurate given how few control datapoints there are, see below math for a better explanation</p>\n",
    "<p>For me, only one datapoint even got higher than positive control 3, so I'll probably stick with normalizing to the average of positive control 3 unless new information comes up about the positive control distributions</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af4f7f08-5029-40d2-877a-072992df82a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resetting, we normalized to the negative controls but are resetting the normalization of the positive controls \n",
    "#Creating copies of the datasets so you can choose which normalization method makes the best sense in context\n",
    "#Only using single data here because frankly that's all that's going to be output anyways\n",
    "\n",
    "paired_data_2 = copy.deepcopy(paired_data)\n",
    "single_data_2 = copy.deepcopy(single_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e982ee1-4451-48d2-aa39-ee587942a455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of all positive controls by positive control, the human 507 one has 3 positive controls \n",
    "#For clarification, each list (ex. pos1) is a list of lists, a list of positive control 1 by each array so they're seperated \n",
    "\n",
    "pos1 = [[] for i in range(amt_dfs)]\n",
    "pos2 = [[] for i in range(amt_dfs)]\n",
    "pos3 = [[] for i in range(amt_dfs)]\n",
    "\n",
    "for i in range(amt_dfs):\n",
    "    for row in paired_data_2[i]:\n",
    "        if row[0] == \"Positive 1\":\n",
    "            pos1[i].append(row[1])\n",
    "        elif row[0] == \"Positive 2\":\n",
    "            pos2[i].append(row[1])\n",
    "        elif row[0] == \"Positive 3\":\n",
    "            pos3[i].append(row[1])\n",
    "\n",
    "#Reading the list (shouldn't be too long), check for outliers here, see above to take out outliers\n",
    "#print(pos1)\n",
    "#print(pos2)\n",
    "#print(pos3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b20d3895-592e-473f-a98c-24c3cad5814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the average of the positive controls that we'll normalize to\n",
    "neg_control0 = 1\n",
    "pos_control1 = [stats.gmean(pos1[i]) for i in range(len(pos1))]\n",
    "pos_control2 = [stats.gmean(pos2[i]) for i in range(len(pos2))]\n",
    "pos_control3 = [stats.gmean(pos3[i]) for i in range(len(pos3))]\n",
    "\n",
    "#Check that average makes sense, revise outliers list if not \n",
    "#print(pos_control1)\n",
    "#print(pos_control2)\n",
    "#print(pos_control3)\n",
    "\n",
    "#remove the positive control values from the paired data, unnecessary to keep them in your final data since we're going to normalize to them\n",
    "single_data_2 = [list(filter(lambda row: row[0] != \"Positive 1\", single_data_2[dataframe])) for dataframe in range(amt_dfs)]\n",
    "single_data_2 = [list(filter(lambda row: row[0] != \"Positive 2\", single_data_2[dataframe])) for dataframe in range(amt_dfs)]\n",
    "single_data_2 = [list(filter(lambda row: row[0] != \"Positive 3\", single_data_2[dataframe])) for dataframe in range(amt_dfs)]\n",
    "\n",
    "#Check that paired data filters properly\n",
    "#print(single_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d0586ea-1ce4-432f-94aa-cdb8546847c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is where the math comes in and normalization begins! \n",
    "\n",
    "for dataframe in range(amt_dfs):\n",
    "    for row in single_data_2[dataframe]: \n",
    "        if (row[1] < neg_control0):\n",
    "            row[1] = 0\n",
    "        elif (row[1] < pos_control3[dataframe]):\n",
    "            row[1] = (row[1]-neg_control0)/(pos_control3[dataframe]-neg_control)\n",
    "        elif (row[1] < pos_control2[dataframe]):\n",
    "            row[1] = 1 + (row[1]-pos_control3[dataframe])/(pos_control2[dataframe]-pos_control3[dataframe])\n",
    "        elif (row[1] < pos_control1[dataframe]):\n",
    "            row[1] = 2 + (row[1]-pos_control2[dataframe])/(pos_control2[dataframe]-pos_control3[dataframe])\n",
    "        else:\n",
    "            row[1] = 3\n",
    "\n",
    "#print(single_data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cff62e5-2c21-4c50-b12c-2229712180eb",
   "metadata": {},
   "source": [
    "<h2>Log Fold Change with our Normalization Method for Graphical and Data Analysis</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5f7438ea-7c1c-446b-8ef4-8efbfe34ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First turn our list of lists into dataframes\n",
    "\n",
    "#Choose which normalization method you want to use (1 or 2)\n",
    "single_data = single_data_1\n",
    "\n",
    "df_of = pd.DataFrame(data = single_data[0])\n",
    "df_yf = pd.DataFrame(data = single_data[1])\n",
    "df_ym = pd.DataFrame(data = single_data[2])\n",
    "df_om = pd.DataFrame(data = single_data[3])\n",
    "\n",
    "df_of = df_of.sort_values(df_of.columns[0], ascending = True, key=lambda col: col.str.lower())\n",
    "df_yf = df_yf.sort_values(df_yf.columns[0], ascending = True, key=lambda col: col.str.lower())\n",
    "df_ym = df_ym.sort_values(df_ym.columns[0], ascending = True, key=lambda col: col.str.lower())\n",
    "df_om = df_om.sort_values(df_om.columns[0], ascending = True, key=lambda col: col.str.lower())\n",
    "\n",
    "#df_of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5572d63f-a5ce-450e-99e7-3fc2f97b601d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Proteins</th>\n",
       "      <th>OF_mean</th>\n",
       "      <th>YF_mean</th>\n",
       "      <th>YM_mean</th>\n",
       "      <th>OM_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6Ckineâ€ </td>\n",
       "      <td>58.931777</td>\n",
       "      <td>24.251110</td>\n",
       "      <td>85.553304</td>\n",
       "      <td>171.231024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Activin Aâ€ </td>\n",
       "      <td>55.766595</td>\n",
       "      <td>23.775622</td>\n",
       "      <td>82.580351</td>\n",
       "      <td>129.118457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Activin B</td>\n",
       "      <td>60.819428</td>\n",
       "      <td>18.067375</td>\n",
       "      <td>69.477694</td>\n",
       "      <td>101.513606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Activin C</td>\n",
       "      <td>215.191493</td>\n",
       "      <td>40.189519</td>\n",
       "      <td>111.615483</td>\n",
       "      <td>184.181059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Activin RIA / ALK-2</td>\n",
       "      <td>141.607466</td>\n",
       "      <td>32.100248</td>\n",
       "      <td>114.646464</td>\n",
       "      <td>198.772832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Proteins     OF_mean    YF_mean     YM_mean     OM_mean\n",
       "0              6Ckineâ€    58.931777  24.251110   85.553304  171.231024\n",
       "1           Activin Aâ€    55.766595  23.775622   82.580351  129.118457\n",
       "2            Activin B   60.819428  18.067375   69.477694  101.513606\n",
       "3            Activin C  215.191493  40.189519  111.615483  184.181059\n",
       "4  Activin RIA / ALK-2  141.607466  32.100248  114.646464  198.772832"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge into one dataframe containing all of the dataframes (technically there's a prettier way to do this and the above codeblock but this also works, I can change it later!)\n",
    "\n",
    "df_of = df_of.rename(columns={0: \"Proteins\", 1: \"OF_mean\"})\n",
    "df_yf = df_yf.rename(columns={0: \"Proteins\", 1: \"YF_mean\"})\n",
    "df_ym = df_ym.rename(columns={0: \"Proteins\", 1: \"YM_mean\"})\n",
    "df_om = df_om.rename(columns={0: \"Proteins\", 1: \"OM_mean\"})\n",
    "\n",
    "df = df_of.merge(df_yf, on=\"Proteins\")\n",
    "df = df.merge(df_ym, on=\"Proteins\")\n",
    "df = df.merge(df_om, on=\"Proteins\")\n",
    "df = df.sort_values(df.columns[0], ascending = True, key=lambda col: col.str.lower())\n",
    "\n",
    "df.to_csv(\"output.csv\") #Output final dataframe if you want to create graphs or do more computation or just show it off elsewhere \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "598cbef9-4d7c-4fad-9954-21f8e74ad528",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add averages, means of the arrays you want to compare, in this case I'm comparing old to young and male to and female\n",
    "\n",
    "df[\"Average Old\"] = (df[\"OM_mean\"] + df[\"OF_mean\"])/2 \n",
    "df[\"Average Young\"] = (df[\"YM_mean\"] + df[\"YF_mean\"])/2 \n",
    "df[\"Average Female\"] = (df[\"OF_mean\"] + df[\"YF_mean\"])/2 \n",
    "df[\"Average Male\"] = (df[\"YM_mean\"] + df[\"OM_mean\"])/2 \n",
    "\n",
    "df[\"Average\"] = df[\"Average Old\"] + df[\"Average Young\"] / 2\n",
    "\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d97b8456-728b-45d6-be1b-9b83cf788a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/lib/python3.11/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Add log fold change calculation, I want to find log fold change of old compared to young so that's what I'm using! But you can add whatever comparisons you want\n",
    "\n",
    "log_fold = df \n",
    "log_fold[\"L2FC\"] = np.log2(log_fold[\"Average Old\"]) - np.log2(log_fold[\"Average Young\"] + 0.0000001)\n",
    "log_fold\n",
    "\n",
    "#For volcano plots \n",
    "\n",
    "#This will just make a dataframe with the protein and log fold change, nothing else for comparison, so you can copy paste to prism or a software that makes log fold change graphs \n",
    "log_fold_final = log_fold.loc[:, [\"Proteins\", \"L2FC\", \"Average\"]]\n",
    "log_fold_final.to_csv(\"logfold.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9266535d-7954-4bb2-a2c6-9469d78f7308",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_91/2428311220.py:26: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sig_list = sig.groupby(\"Proteins\").apply(lambda df: stats.ttest_ind(df['Old'], df['Young'], alternative='two-sided')[1]).sort_values()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proteins</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IL-17C</th>\n",
       "      <td>1.724329e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HB-EGF</th>\n",
       "      <td>3.170862e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMP-7â€ </th>\n",
       "      <td>2.830215e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMP-8â€ </th>\n",
       "      <td>5.914439e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IL-1 raâ€ </th>\n",
       "      <td>7.682107e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "Proteins              \n",
       "IL-17C    1.724329e-07\n",
       "HB-EGF    3.170862e-06\n",
       "MMP-7â€     2.830215e-05\n",
       "MMP-8â€     5.914439e-05\n",
       "IL-1 raâ€   7.682107e-05"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list in order of significance \n",
    "\n",
    "all_dfs_df = [pd.DataFrame(df) for df in all_dfs]\n",
    "all_dfs_df2 = [df[\"F532 Total Intensity\"] for df in all_dfs_df]\n",
    "all_dfs_df2.append(all_dfs_df[0][\"ID\"])\n",
    "\n",
    "significance_df = pd.concat(all_dfs_df2, axis=1, ignore_index=True)\n",
    "significance_df.columns = [\"OF\", \"YF\", \"YM\", \"OM\", \"Proteins\"]\n",
    "\n",
    "#normalized to positive 3 control\n",
    "\n",
    "significance_df[\"OF\"] = (significance_df[\"OF\"]/neg_control[0]) / pos_control[0]\n",
    "significance_df[\"YF\"] = (significance_df[\"YF\"]/neg_control[1]) / pos_control[1]\n",
    "significance_df[\"YM\"] = (significance_df[\"YM\"]/neg_control[2]) / pos_control[2]\n",
    "significance_df[\"OM\"] = (significance_df[\"OM\"]/neg_control[3]) / pos_control[3]\n",
    "\n",
    "#calculate t test from significance_df, have to rework everything lol \n",
    "\n",
    "old = pd.DataFrame(list(significance_df[\"OF\"]) + list(significance_df[\"OM\"]))\n",
    "young = pd.DataFrame(list(significance_df[\"YF\"]) + list(significance_df[\"YM\"]))\n",
    "proteins = pd.DataFrame(list(significance_df[\"Proteins\"]) + list(significance_df[\"Proteins\"]))\n",
    "\n",
    "sig = pd.concat([old, young, proteins], axis=1, ignore_index=True)\n",
    "sig.columns = [\"Old\", \"Young\", \"Proteins\"]\n",
    "\n",
    "sig_list = sig.groupby(\"Proteins\").apply(lambda df: stats.ttest_ind(df['Old'], df['Young'], alternative='two-sided')[1]).sort_values()\n",
    "sig_dataframe = pd.DataFrame(sig_list)\n",
    "\n",
    "sig_dataframe.to_csv(\"significance.csv\")\n",
    "sig_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e326e3-e8e4-4078-9092-035462ce82cd",
   "metadata": {},
   "source": [
    "<h2>End of Normalization and Calculations</h2>\n",
    "<h4>I used Prism for visualization.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488d6cdd-9269-4d57-878a-8df7fea00ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
